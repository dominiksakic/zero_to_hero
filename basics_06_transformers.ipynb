{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMK9NhpM967r2cWWOYcf6Pc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominiksakic/zero_to_hero/blob/main/basics_06_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- source: https://www.youtube.com/watch?v=kCc8FmEb1nY&t=126s"
      ],
      "metadata": {
        "id": "1CQwLj_P358I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "dTxy15zCh0e-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get data\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "id": "HAYtmhDA4dIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b6dfac-9736-475c-c7f0-ab700a3039f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-19 07:19:32--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-07-19 07:19:32 (22.5 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3YdWReGDPJU",
        "outputId": "c509aeb3-28a3-457f-848e-42d7225517d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make decoder, encoder\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "stoi = {ch:i  for i, ch in enumerate(chars)}\n",
        "itos = {i : ch for i, ch in enumerate(chars)}\n",
        "\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "print(encode(text[:50]))\n",
        "print(decode(encode(text[:50])))\n",
        "print(f\"Vocav size: {vocab_size}\")"
      ],
      "metadata": {
        "id": "KZM0-heV4e6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5b59ee-cd75-4c64-ca15-b69588b1e420"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56]\n",
            "First Citizen:\n",
            "Before we proceed any further, hear\n",
            "Vocav size: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize data, and create test/val\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "cYzUPM-MFc5A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# excursion into how the model predicts next token from one sentence\n",
        "block_size = 8\n",
        "\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]  #<---\n",
        "    target = y[t]\n",
        "    print(f'timestep {t}: when input is {context} the target is {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xmBBuSeiwmV",
        "outputId": "d1f4141d-32f4-4d4b-de50-8cf219c31eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timestep 0: when input is tensor([18]) the target is 47\n",
            "timestep 1: when input is tensor([18, 47]) the target is 56\n",
            "timestep 2: when input is tensor([18, 47, 56]) the target is 57\n",
            "timestep 3: when input is tensor([18, 47, 56, 57]) the target is 58\n",
            "timestep 4: when input is tensor([18, 47, 56, 57, 58]) the target is 1\n",
            "timestep 5: when input is tensor([18, 47, 56, 57, 58,  1]) the target is 15\n",
            "timestep 6: when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is 47\n",
            "timestep 7: when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Result is that the model learns to complete from various lengths.\n",
        "  - from one characters up to 8.\n"
      ],
      "metadata": {
        "id": "HKrQTbilkhsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets make the example more complex by introducing a batch dimension\n",
        "torch.manual_seed(1337)\n",
        "batch_size = 4\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+ block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "\n",
        "for b in range(batch_size):\n",
        "  for t in range(block_size):\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b, t]\n",
        "\n",
        "    print(f\"Batch {b}: when context is {context}, target is {target}\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHVN5K7DkLc7",
        "outputId": "d6606924-9b3a-4de0-c1e7-18b779f370aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0: when context is tensor([24]), target is 43\n",
            "Batch 0: when context is tensor([24, 43]), target is 58\n",
            "Batch 0: when context is tensor([24, 43, 58]), target is 5\n",
            "Batch 0: when context is tensor([24, 43, 58,  5]), target is 57\n",
            "Batch 0: when context is tensor([24, 43, 58,  5, 57]), target is 1\n",
            "Batch 0: when context is tensor([24, 43, 58,  5, 57,  1]), target is 46\n",
            "Batch 0: when context is tensor([24, 43, 58,  5, 57,  1, 46]), target is 43\n",
            "Batch 0: when context is tensor([24, 43, 58,  5, 57,  1, 46, 43]), target is 39\n",
            "\n",
            "\n",
            "Batch 1: when context is tensor([44]), target is 53\n",
            "Batch 1: when context is tensor([44, 53]), target is 56\n",
            "Batch 1: when context is tensor([44, 53, 56]), target is 1\n",
            "Batch 1: when context is tensor([44, 53, 56,  1]), target is 58\n",
            "Batch 1: when context is tensor([44, 53, 56,  1, 58]), target is 46\n",
            "Batch 1: when context is tensor([44, 53, 56,  1, 58, 46]), target is 39\n",
            "Batch 1: when context is tensor([44, 53, 56,  1, 58, 46, 39]), target is 58\n",
            "Batch 1: when context is tensor([44, 53, 56,  1, 58, 46, 39, 58]), target is 1\n",
            "\n",
            "\n",
            "Batch 2: when context is tensor([52]), target is 58\n",
            "Batch 2: when context is tensor([52, 58]), target is 1\n",
            "Batch 2: when context is tensor([52, 58,  1]), target is 58\n",
            "Batch 2: when context is tensor([52, 58,  1, 58]), target is 46\n",
            "Batch 2: when context is tensor([52, 58,  1, 58, 46]), target is 39\n",
            "Batch 2: when context is tensor([52, 58,  1, 58, 46, 39]), target is 58\n",
            "Batch 2: when context is tensor([52, 58,  1, 58, 46, 39, 58]), target is 1\n",
            "Batch 2: when context is tensor([52, 58,  1, 58, 46, 39, 58,  1]), target is 46\n",
            "\n",
            "\n",
            "Batch 3: when context is tensor([25]), target is 17\n",
            "Batch 3: when context is tensor([25, 17]), target is 27\n",
            "Batch 3: when context is tensor([25, 17, 27]), target is 10\n",
            "Batch 3: when context is tensor([25, 17, 27, 10]), target is 0\n",
            "Batch 3: when context is tensor([25, 17, 27, 10,  0]), target is 21\n",
            "Batch 3: when context is tensor([25, 17, 27, 10,  0, 21]), target is 1\n",
            "Batch 3: when context is tensor([25, 17, 27, 10,  0, 21,  1]), target is 54\n",
            "Batch 3: when context is tensor([25, 17, 27, 10,  0, 21,  1, 54]), target is 39\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a baseline model/bigram\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "      # idx is (B, T) array of indices in the current context\n",
        "      for _ in range(max_new_tokens):\n",
        "          # get the predictions\n",
        "          logits, loss = self(idx)\n",
        "          # focus only on the last time step\n",
        "          logits = logits[:, -1, :] # becomes (B, C)\n",
        "          # apply softmax to get probabilities\n",
        "          probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "          # sample from the distribution\n",
        "          idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "          # append sampled index to the running sequence\n",
        "          idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "      return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss.item())\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=50)[0].tolist()))"
      ],
      "metadata": {
        "id": "sq74fs6T4jRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97276b8e-0f18-4bbf-8967-f94ab86e771f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 65])\n",
            "4.648044586181641\n",
            "\n",
            "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "tT77wDlCwRc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the baseline\n",
        "batch_size = 32\n",
        "\n",
        "for s in range(100000):\n",
        "  # trainig data\n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  # Forward pass\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "  #Backward pass\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "KgPcGM_C4qxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3c0944-4536-4240-a524-92c7f1d82eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4081521034240723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample after training\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "id": "zLVzI3sewo5M",
        "outputId": "ac2a1af6-147e-483d-a8fd-78f1d5b10e3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "MAUEdingn I\n",
            "GBENoutl, Thasuriopro sorllll le.\n",
            "\n",
            "Mat,\n",
            "FI s ICKI ambe mithevis LLEShe ysste ar s blllyorswon\n",
            "Clmbe t uruk\n",
            "CLLarf w p ar lye twemen ulif hercefowive:\n",
            "YBOUSTIOVO: gh ced s p ay anore iveatothe ierave yanccu wind s; oalllak omad ste?\n",
            "h;\n",
            "\n",
            "JUThow h llde iouge thes whe yomeathistlieis moma hit me o ind.\n",
            "\n",
            "F hik, thite:\n",
            "TRThe hal at w!\n",
            "Whase t ma T:\n",
            "\n",
            "Bareomast yethin athe stt geloupr msh f wh n\n",
            "Yorinkeshave pan t,\n",
            "NGAnthe or,\n",
            "Wh tro joullieallisube:\n",
            "Fin matthese V:\n",
            "Aporn geng y ll yr mofor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xv, yv = get_batch(\"val\")\n",
        "_, loss = m(xv, yv)\n",
        "\n",
        "print(f\"Validation loss: {loss}\")"
      ],
      "metadata": {
        "id": "b18GafH2y0Pl",
        "outputId": "43eaa13c-b5eb-4d99-860d-6cae2cf90a47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.419926404953003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers\n"
      ],
      "metadata": {
        "id": "2VzQyQH74vTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gensis of Transformer (weighted aggregation)\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "print('Starting Tensor a')\n",
        "print({a})\n",
        "\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "print(f'\\nShape of a: {a.shape}')\n",
        "print('Divide values by the sum along the 1 axis: ')\n",
        "print({a})\n",
        "\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "print(f'\\nShape of b: {b.shape}')\n",
        "print('Starting tensor b is')\n",
        "print(b)\n",
        "\n",
        "c = a @ b\n",
        "print('\\nresult of c is')\n",
        "print(c)\n"
      ],
      "metadata": {
        "id": "wqRqB4f842tM",
        "outputId": "371f48f8-42af-4619-b0d1-92ef6f35b550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Tensor a\n",
            "{tensor([[1., 0., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 1.]])}\n",
            "\n",
            "Shape of a: torch.Size([3, 3])\n",
            "Divide values by the sum along the 1 axis: \n",
            "{tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])}\n",
            "\n",
            "Shape of b: torch.Size([3, 2])\n",
            "Starting tensor b is\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "\n",
            "result of c is\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "print(f'Batch 0')\n",
        "print(x[0])"
      ],
      "metadata": {
        "id": "jXZolVEdSaRY",
        "outputId": "2c722aca-47d2-40c8-faeb-6a37fe3725c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0\n",
            "tensor([[ 0.1808, -0.0700],\n",
            "        [-0.3596, -0.9152],\n",
            "        [ 0.6258,  0.0255],\n",
            "        [ 0.9545,  0.0643],\n",
            "        [ 0.3612,  1.1679],\n",
            "        [-1.3499, -0.5102],\n",
            "        [ 0.2360, -0.2398],\n",
            "        [-0.9211,  1.5433]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    print(f'Batch: {b}')\n",
        "    for t in range(T):\n",
        "      xprev = x[b, :t+1]\n",
        "      xbow[b,t] = torch.mean(xprev, 0)\n",
        "      print(f'time step {t}, after aggregation: {xbow[b,t]}')\n",
        "\n",
        "    if b == 0:\n",
        "      break"
      ],
      "metadata": {
        "id": "QGe66qnRSc_Q",
        "outputId": "cea20ac4-c5ef-4005-d360-740e959b1fd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0\n",
            "time step 0, after aggregation: tensor([ 0.1808, -0.0700])\n",
            "time step 1, after aggregation: tensor([-0.0894, -0.4926])\n",
            "time step 2, after aggregation: tensor([ 0.1490, -0.3199])\n",
            "time step 3, after aggregation: tensor([ 0.3504, -0.2238])\n",
            "time step 4, after aggregation: tensor([0.3525, 0.0545])\n",
            "time step 5, after aggregation: tensor([ 0.0688, -0.0396])\n",
            "time step 6, after aggregation: tensor([ 0.0927, -0.0682])\n",
            "time step 7, after aggregation: tensor([-0.0341,  0.1332])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For each time step we want to have the previous timesteps accumulated(mean)"
      ],
      "metadata": {
        "id": "0e_9rOeHVFIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "print(f'shape of wei: {wei.shape}')\n",
        "print(f'wei is: {wei}')\n",
        "\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "print(f'\\nwei after normalization: {wei}')\n",
        "\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "print(f'\\nxbow2 batch 0 after multiplication: {xbow2[0]}')\n"
      ],
      "metadata": {
        "id": "JtrOgIJUVODO",
        "outputId": "c6c93403-df45-46c6-dadf-f80d641d394e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of wei: torch.Size([8, 8])\n",
            "wei is: tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "\n",
            "wei after normalization: tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
            "\n",
            "xbow2 batch 0 after multiplication: tensor([[ 0.1808, -0.0700],\n",
            "        [-0.0894, -0.4926],\n",
            "        [ 0.1490, -0.3199],\n",
            "        [ 0.3504, -0.2238],\n",
            "        [ 0.3525,  0.0545],\n",
            "        [ 0.0688, -0.0396],\n",
            "        [ 0.0927, -0.0682],\n",
            "        [-0.0341,  0.1332]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "print(f'tril: {tril}')\n",
        "\n",
        "wei = torch.zeros((T,T))\n",
        "print(f'\\nwei: {wei}')\n",
        "\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "print(f'\\nwei after masking: {wei}')\n",
        "\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(f'\\nwei after softmax: {wei}')\n",
        "\n",
        "xbow3 = wei @ x\n",
        "print(f'\\nxbow3 batch 0: {xbow3[0]}')"
      ],
      "metadata": {
        "id": "EMTlN_p-V95N",
        "outputId": "644ae5a9-90ff-4424-e8af-5c06dde34387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tril: tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "\n",
            "wei: tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "\n",
            "wei after masking: tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "\n",
            "wei after softmax: tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
            "\n",
            "xbow3 batch 0: tensor([[ 0.1808, -0.0700],\n",
            "        [-0.0894, -0.4926],\n",
            "        [ 0.1490, -0.3199],\n",
            "        [ 0.3504, -0.2238],\n",
            "        [ 0.3525,  0.0545],\n",
            "        [ 0.0688, -0.0396],\n",
            "        [ 0.0927, -0.0682],\n",
            "        [-0.0341,  0.1332]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 4: self-attention!\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# single Head\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False) # what I am asking about\n",
        "query = nn.Linear(C, head_size, bias=False) # waht others offer\n",
        "value = nn.Linear(C, head_size, bias=False) # what others contain\n",
        "# The original input vector 32-dimension gets mapped inot a smaller space\n",
        "k = key(x)   # B, T, 16\n",
        "q = query(x) # B, T, 16\n",
        "\n",
        "# Attention scores for every position with each other\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "\n",
        "# mask future tokens, for autoregressive models\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "# weighted sums of values/contextualization\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "#out = wei @ x\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "id": "ht2LPyS0e_ie",
        "outputId": "af3b208c-1283-4af3-8ccf-6206097e7c06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "id": "d3YHqM2JfJSp",
        "outputId": "5e5ff289-007e-43a6-d614-95cad32b3162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
              "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
              "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Solving the transpose mystery(for me)\n",
        "B,T,C = 1,2,4\n",
        "x = torch.randn(B,T,C)\n",
        "print(f'x: \\n{x}\\n')\n",
        "\n",
        "head_size = 3\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)\n",
        "q = query(x)\n",
        "\n",
        "print(f'key: \\n{key}\\n')\n",
        "print(f'k: \\n{k}\\n')\n",
        "\n",
        "# Question why cant I just do q @ k  = (1,2,3) @ (1,2,3)\n",
        "# Answer the inner dimension dont align (2,3) @ (2,3)\n",
        "\"\"\"\n",
        "              x11 x12 x123\n",
        "              x21 x22 x223\n",
        "x11 x12 x123\n",
        "x21 x22 x223\n",
        "\n",
        "== not possible thus swap the last layer (-1) and the one before(-2)\n",
        "\n",
        "              x11 x21\n",
        "              x12 x22\n",
        "              x13 x23\n",
        "x12 x22 x123\n",
        "x21 x22 x223\n",
        "\"\"\"\n",
        "print(f'before: k values: \\n{k}\\n')\n",
        "print(f'after: k values: \\n{k.transpose(-2, -1)}\\n')\n"
      ],
      "metadata": {
        "id": "IRs-k5URitzR",
        "outputId": "d0e54604-2dc5-42b4-d8d9-7d3ed317d3d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: \n",
            "tensor([[[ 1.0729, -0.5504,  0.4417,  1.8560],\n",
            "         [-1.6223, -1.8155, -0.8447, -2.1575]]])\n",
            "\n",
            "key: \n",
            "Linear(in_features=4, out_features=3, bias=False)\n",
            "\n",
            "k: \n",
            "tensor([[[-0.8246,  0.3190,  0.2538],\n",
            "         [-0.1150, -0.0447,  0.1061]]], grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "before: k values: \n",
            "tensor([[[-0.8246,  0.3190,  0.2538],\n",
            "         [-0.1150, -0.0447,  0.1061]]], grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "after: k values: \n",
            "tensor([[[-0.8246, -0.1150],\n",
            "         [ 0.3190, -0.0447],\n",
            "         [ 0.2538,  0.1061]]], grad_fn=<TransposeBackward0>)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes from Andrej:\n",
        "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
        "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
        "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
        "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
        "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
        "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
      ],
      "metadata": {
        "id": "0SjUoDo6luOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.randn(B,T,head_size)\n",
        "q = torch.randn(B,T,head_size)\n",
        "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
      ],
      "metadata": {
        "id": "MiB_nVXdl8nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.var()"
      ],
      "metadata": {
        "id": "fIWORJcql900",
        "outputId": "9493b0a4-d87a-469c-efd1-23033ba445da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.3187)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q.var()"
      ],
      "metadata": {
        "id": "64zTkvQbl-6r",
        "outputId": "bb6b0152-510e-4ffd-a6f6-0ebd5c047cd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6392)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei.var()"
      ],
      "metadata": {
        "id": "MQwTEh-1l_4b",
        "outputId": "545d3f5a-0141-4b63-d68e-63d1dc2b8c6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3140)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
      ],
      "metadata": {
        "id": "rnEqA5uImB3P",
        "outputId": "2680feca-d300-4e73-deff-207474f4fe7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"
      ],
      "metadata": {
        "id": "IsEh4iK0mD1a",
        "outputId": "08bb9295-e5f7-4f82-8f66-36cd1f45da46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code"
      ],
      "metadata": {
        "id": "aBZ06HAvp9HF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "E4Qvht4EqPOs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "UicJXm5NrgLi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Papers about positional embeddings:\n",
        "- https://arxiv.org/abs/1810.04805\n",
        "- https://arxiv.org/abs/1803.02155\n",
        "- https://arxiv.org/abs/2104.09864\n",
        "- https://arxiv.org/abs/2002.12327"
      ],
      "metadata": {
        "id": "ghgXa-aNSco-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Probing into position_embedding_table\n",
        "text_chunk = encode(text[:32])\n",
        "block_size = 32\n",
        "vocab_size = 65\n",
        "n_embd = 64\n",
        "\n",
        "token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "\n",
        "idx = torch.tensor(text_chunk).unsqueeze(0)\n",
        "B, T = idx.shape\n",
        "print(f\"{idx.shape}\\n\")\n",
        "\n",
        "print(f\"Before encoding: {text[:32]}\\n\")\n",
        "print(f\"After encoding : {text_chunk}\\n\")\n",
        "print(f'token_embedding_table: \\n    -{token_embedding_table}\\n') # ---> B,T in B, T, C out // plucking the rows outs\n",
        "print(f'position_embedding_table: \\n    -{position_embedding_table}\\n')\n",
        "\n",
        "\n",
        "tok_emb = token_embedding_table(idx) # (B,T,C)\n",
        "pos_emb = position_embedding_table(torch.arange(T, )) # (T,C)\n",
        "x = tok_emb + pos_emb # (B,T,C)\n",
        "\n",
        "print(f\"tok_emb shape: {tok_emb.shape}\")\n",
        "print(f\"pos_emb shape: {pos_emb.shape}\")\n",
        "print(f\"Result of tok_emb +  pos_emb: {x.shape}\\n\")\n",
        "\n",
        "print(\"Embeddings for the letter i\")\n",
        "print(tok_emb[:,1:2,:])\n",
        "\n",
        "print(\"\\nPosition embedding for the second letter i\")\n",
        "print(pos_emb[1])\n",
        "\n",
        "print(\"\\nPosition embedding for the seventh letter i\")\n",
        "print(pos_emb[7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE9fB-1jH-o9",
        "outputId": "2971e0c1-bc05-4162-e45a-98d2e2947a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32])\n",
            "\n",
            "Before encoding: First Citizen:\n",
            "Before we proceed\n",
            "\n",
            "After encoding : [18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42]\n",
            "\n",
            "token_embedding_table: \n",
            "    -Embedding(65, 64)\n",
            "\n",
            "position_embedding_table: \n",
            "    -Embedding(32, 64)\n",
            "\n",
            "tok_emb shape: torch.Size([1, 32, 64])\n",
            "pos_emb shape: torch.Size([32, 64])\n",
            "Result of tok_emb +  pos_emb: torch.Size([1, 32, 64])\n",
            "\n",
            "Embeddings for the letter i\n",
            "tensor([[[ 0.3328,  0.0923, -1.1710, -0.3889, -0.0586,  0.7351, -0.2375,\n",
            "          -0.0794,  0.1304, -0.3239, -1.0098,  0.9415, -1.0418,  0.5966,\n",
            "           0.9954,  0.3853,  0.5848, -0.3529, -0.9835,  0.9844, -0.3214,\n",
            "          -2.2650,  0.3112,  1.0370, -0.2482,  0.2878,  0.1709,  0.2090,\n",
            "           0.3340, -0.2204,  2.2747, -0.7287,  0.1802,  1.7495, -2.3586,\n",
            "           0.9739,  0.0316,  0.2331,  0.7056, -1.3177, -1.2374, -0.4133,\n",
            "          -0.6679,  1.1041, -1.1024, -0.1291,  1.2628,  0.0929,  1.2860,\n",
            "          -0.7879, -0.0096,  0.9879, -2.3441,  1.1441,  0.5141,  0.9583,\n",
            "           0.6715, -0.0498, -0.3968,  1.3753,  1.7860, -0.1942, -0.0502,\n",
            "           0.2560]]], grad_fn=<SliceBackward0>)\n",
            "\n",
            "Position embedding for the second letter i\n",
            "tensor([ 1.2379e+00,  8.1566e-01,  8.7645e-02,  9.4933e-01,  5.9643e-02,\n",
            "         2.6767e+00, -4.8159e-01, -4.4165e-01,  2.1165e+00,  5.5407e-01,\n",
            "        -1.1866e-01,  1.2752e-01,  2.7119e-01,  1.4236e+00,  3.8732e-01,\n",
            "        -6.6658e-01,  1.5317e+00,  2.1207e-01, -2.5556e-01, -3.5850e-01,\n",
            "        -1.3526e+00,  1.5514e-01, -4.2101e-01,  4.2674e-01,  6.3459e-02,\n",
            "         2.6628e-01,  1.1508e-01, -8.3262e-01, -9.4887e-01,  9.2167e-01,\n",
            "        -1.6605e+00,  1.0328e+00, -1.4315e-01,  1.3606e+00,  2.0193e+00,\n",
            "        -2.3949e+00,  8.6343e-01, -2.1536e+00, -3.7635e-01,  1.1467e-01,\n",
            "         9.2188e-01,  3.4551e-01,  7.0556e-04,  1.3733e+00,  3.9286e-01,\n",
            "        -5.0163e-01,  3.9642e-01, -6.8734e-01, -2.6801e-01,  1.3199e+00,\n",
            "        -8.5489e-01,  1.9043e-01, -7.2852e-01,  1.0641e+00, -3.8654e-01,\n",
            "         8.8774e-01, -1.2779e-01, -6.2829e-01,  1.0278e+00,  8.0930e-01,\n",
            "         5.8418e-01,  5.2161e-01, -1.1608e+00,  9.1046e-01],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "\n",
            "Position embedding for the seventh letter i\n",
            "tensor([-0.6059, -1.3237, -1.1769,  0.6769,  0.7560,  1.0867, -0.4872,  1.0163,\n",
            "        -2.1321,  0.3759, -1.8666, -1.6417, -1.1986,  0.1526, -0.0806,  0.5709,\n",
            "         0.7054,  1.0700, -0.0180, -0.2065, -2.0208, -0.9383, -1.3161, -0.2102,\n",
            "        -0.7993, -0.1255, -0.0462, -0.7618, -2.0773,  0.5378, -0.8806, -1.1450,\n",
            "         0.0533, -0.7391,  1.2248, -0.7025, -0.5837,  0.2112, -1.9684,  1.0273,\n",
            "         0.3660,  0.0860, -0.6697, -0.3467, -1.2340,  0.3927, -1.0097,  0.3583,\n",
            "         1.9938,  1.7935,  1.9588, -0.2359, -2.3815,  1.5746, -0.2365, -0.8718,\n",
            "         1.1227,  1.8145,  1.1775,  0.8223,  0.6202,  0.0863,  1.2622,  0.0381],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "\n",
        "torch.manual_seed(1337)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szPwjUXNp8UJ",
        "outputId": "c69a9984-743f-47c7-df45-1837212014de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d45a83e5790>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ],
      "metadata": {
        "id": "EriBuypurMNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn4rUmSUrNhA",
        "outputId": "e92a4042-8261-4b84-fcf9-680c6156f189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.209729 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "xcJDwCyxrPk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGAWoY5vrRQ3",
        "outputId": "573eafd8-0164-4ec1-fd66-98d86519033c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.4116, val loss 4.4022\n",
            "step 100: train loss 2.6568, val loss 2.6670\n",
            "step 200: train loss 2.5090, val loss 2.5058\n",
            "step 300: train loss 2.4197, val loss 2.4337\n",
            "step 400: train loss 2.3501, val loss 2.3562\n",
            "step 500: train loss 2.2965, val loss 2.3127\n",
            "step 600: train loss 2.2412, val loss 2.2502\n",
            "step 700: train loss 2.2053, val loss 2.2196\n",
            "step 800: train loss 2.1631, val loss 2.1862\n",
            "step 900: train loss 2.1233, val loss 2.1499\n",
            "step 1000: train loss 2.1035, val loss 2.1306\n",
            "step 1100: train loss 2.0688, val loss 2.1182\n",
            "step 1200: train loss 2.0383, val loss 2.0801\n",
            "step 1300: train loss 2.0240, val loss 2.0645\n",
            "step 1400: train loss 1.9929, val loss 2.0366\n",
            "step 1500: train loss 1.9699, val loss 2.0311\n",
            "step 1600: train loss 1.9599, val loss 2.0447\n",
            "step 1700: train loss 1.9396, val loss 2.0123\n",
            "step 1800: train loss 1.9080, val loss 1.9932\n",
            "step 1900: train loss 1.9080, val loss 1.9860\n",
            "step 2000: train loss 1.8818, val loss 1.9941\n",
            "step 2100: train loss 1.8714, val loss 1.9764\n",
            "step 2200: train loss 1.8574, val loss 1.9599\n",
            "step 2300: train loss 1.8526, val loss 1.9496\n",
            "step 2400: train loss 1.8403, val loss 1.9420\n",
            "step 2500: train loss 1.8145, val loss 1.9424\n",
            "step 2600: train loss 1.8271, val loss 1.9403\n",
            "step 2700: train loss 1.8112, val loss 1.9291\n",
            "step 2800: train loss 1.8040, val loss 1.9210\n",
            "step 2900: train loss 1.8043, val loss 1.9287\n",
            "step 3000: train loss 1.7937, val loss 1.9174\n",
            "step 3100: train loss 1.7678, val loss 1.9148\n",
            "step 3200: train loss 1.7543, val loss 1.9102\n",
            "step 3300: train loss 1.7547, val loss 1.9030\n",
            "step 3400: train loss 1.7541, val loss 1.8932\n",
            "step 3500: train loss 1.7367, val loss 1.8976\n",
            "step 3600: train loss 1.7235, val loss 1.8854\n",
            "step 3700: train loss 1.7267, val loss 1.8813\n",
            "step 3800: train loss 1.7199, val loss 1.8882\n",
            "step 3900: train loss 1.7217, val loss 1.8716\n",
            "step 4000: train loss 1.7121, val loss 1.8559\n",
            "step 4100: train loss 1.7101, val loss 1.8755\n",
            "step 4200: train loss 1.7061, val loss 1.8631\n",
            "step 4300: train loss 1.7001, val loss 1.8465\n",
            "step 4400: train loss 1.7049, val loss 1.8616\n",
            "step 4500: train loss 1.6904, val loss 1.8478\n",
            "step 4600: train loss 1.6833, val loss 1.8277\n",
            "step 4700: train loss 1.6808, val loss 1.8452\n",
            "step 4800: train loss 1.6695, val loss 1.8453\n",
            "step 4900: train loss 1.6701, val loss 1.8369\n",
            "step 4999: train loss 1.6616, val loss 1.8201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUcG1ZV7rSaV",
        "outputId": "a2753858-b5b8-4b2d-aab3-b47f7e84153a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "KING RICHAND II:\n",
            "Shall by become to musbe doest thrust the gate\n",
            "My art that usque, God?\n",
            "\n",
            "MEXENES:\n",
            "Butwere my feanst, I zormur\n",
            "Yourselfom in heart mile dill, at misters, I in latient,\n",
            "Worsts, and the now our was twells no me upolds;\n",
            "Hond my sprunt as speak you: none\n",
            "In Boyanterioly home.\n",
            "Who like agaion,---And thee, by we still,\n",
            "His The shience poor of his but\n",
            "that nobrurtef so;\n",
            "Angint my monte in excations, Pried my of.\n",
            "\n",
            "HENRY BOLINGBROY::\n",
            "Saday Warwick to Bauintchir accanny, rents I am you!\n",
            "My fireass, I may.\n",
            "And your gament so a cempres-ennome.\n",
            "\n",
            "GLOUCESTER:\n",
            "Your may in son thee, bod, with confessy.\n",
            "Which migh.\n",
            "\n",
            "ANCAMrown:\n",
            "My when.\n",
            "\n",
            "LARIAPNA:\n",
            "Well, to imdut?\n",
            "\n",
            "LUCIO:\n",
            "For it?\n",
            "Youse so upon surre eRpetALE:\n",
            "What's I have nows: will hear news our house,\n",
            "Havake but fravius wran some. Do selsemmader scolly not\n",
            "To yourself I surre desing\n",
            "My sirre's med Cadius\n",
            "festing of time the shows tears man ip you ou what that that saw\n",
            "Of Becoln madon so hand reford.\n",
            "But I love, wout is forcest, in ginvers road,\n",
            "And you all, I hursend; go wher tcough, do did titance and to you or love\n",
            "As be rews mines so men: by not, it-sonfitgrant of word,\n",
            "And a borrow\n",
            "Her his enIndred a canity to may ince anysing.\n",
            "\n",
            "LADY GAUMET:\n",
            "Look, Reingue, man't my have eath I die;\n",
            "Save thou for Henry fampertle; I\n",
            "Have my of thee tremes deed of through he crown,\n",
            "Nor be nie is clity beloser Wonduntal on the have beguar\n",
            "Good vonsure to you, must a becamen them the deenust om Three;\n",
            "Thy matter! How scowe you,\n",
            "But wolldly tondering; I sokes soul be\n",
            "the shaltesss;\n",
            "River thou a-latscess:\n",
            "Out.\n",
            "\n",
            "PORABELLA:\n",
            "My, Boring strar\n",
            "Egve waced being have Lary.\n",
            "\n",
            "BUMNTANUS:\n",
            "\n",
            "'Twas may-marrishn. Caw't,\n",
            "Garity give affive you his, by assince;\n",
            "I'll his shaw well rivoid: the wife\n",
            "Onger with I have I divoilt, of munders.\n",
            "\n",
            "PLAUY:\n",
            "Hou twhere with you\n",
            "Talk'd our twould you her, to life he pusint\n",
            "It. Titters, and were in of not your your son!\n",
            "Nor am-nsent, Joar at ween of to,\n",
            "Thre Riparding: I wills men's fortundeet,\n",
            "Ame of the viirtuou\n",
            "all \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ffq_dvkLqP6p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out"
      ],
      "metadata": {
        "id": "gXuIBe0Yq0Oc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "j_LM_lI2q-1M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "HPjUdzi7rDeg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "id": "BXzJM_MmtrCG",
        "outputId": "3fe6275c-d40a-4c61-fe02-ec016390ea92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.209729 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "6zOBPfQwtutH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "EHuP2zoLtym5",
        "outputId": "04e8bfc9-3d60-45fd-e93d-06a65ae4c68f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.1999, val loss 4.2014\n",
            "step 100: train loss 2.6165, val loss 2.6175\n",
            "step 200: train loss 2.4788, val loss 2.4753\n",
            "step 300: train loss 2.3859, val loss 2.3917\n",
            "step 400: train loss 2.3474, val loss 2.3619\n",
            "step 500: train loss 2.2928, val loss 2.3048\n",
            "step 600: train loss 2.2332, val loss 2.2614\n",
            "step 700: train loss 2.2060, val loss 2.2439\n",
            "step 800: train loss 2.1516, val loss 2.1810\n",
            "step 900: train loss 2.1103, val loss 2.1427\n",
            "step 1000: train loss 2.0811, val loss 2.1371\n",
            "step 1100: train loss 2.0558, val loss 2.0903\n",
            "step 1200: train loss 2.0118, val loss 2.0513\n",
            "step 1300: train loss 1.9939, val loss 2.0645\n",
            "step 1400: train loss 1.9722, val loss 2.0553\n",
            "step 1500: train loss 1.9288, val loss 2.0244\n",
            "step 1600: train loss 1.9200, val loss 2.0165\n",
            "step 1700: train loss 1.9010, val loss 2.0007\n",
            "step 1800: train loss 1.8945, val loss 1.9957\n",
            "step 1900: train loss 1.8655, val loss 1.9750\n",
            "step 2000: train loss 1.8535, val loss 1.9823\n",
            "step 2100: train loss 1.8311, val loss 1.9684\n",
            "step 2200: train loss 1.8280, val loss 1.9436\n",
            "step 2300: train loss 1.8230, val loss 1.9478\n",
            "step 2400: train loss 1.7946, val loss 1.9331\n",
            "step 2500: train loss 1.7905, val loss 1.9431\n",
            "step 2600: train loss 1.7791, val loss 1.9251\n",
            "step 2700: train loss 1.7737, val loss 1.8995\n",
            "step 2800: train loss 1.7668, val loss 1.8991\n",
            "step 2900: train loss 1.7649, val loss 1.8955\n",
            "step 3000: train loss 1.7391, val loss 1.8814\n",
            "step 3100: train loss 1.7592, val loss 1.9018\n",
            "step 3200: train loss 1.7385, val loss 1.8853\n",
            "step 3300: train loss 1.7264, val loss 1.8544\n",
            "step 3400: train loss 1.7293, val loss 1.8761\n",
            "step 3500: train loss 1.7171, val loss 1.8596\n",
            "step 3600: train loss 1.6990, val loss 1.8575\n",
            "step 3700: train loss 1.7064, val loss 1.8661\n",
            "step 3800: train loss 1.6987, val loss 1.8565\n",
            "step 3900: train loss 1.6954, val loss 1.8386\n",
            "step 4000: train loss 1.6889, val loss 1.8563\n",
            "step 4100: train loss 1.6848, val loss 1.8484\n",
            "step 4200: train loss 1.6900, val loss 1.8396\n",
            "step 4300: train loss 1.6861, val loss 1.8384\n",
            "step 4400: train loss 1.6688, val loss 1.8207\n",
            "step 4500: train loss 1.6731, val loss 1.8076\n",
            "step 4600: train loss 1.6748, val loss 1.8128\n",
            "step 4700: train loss 1.6609, val loss 1.8124\n",
            "step 4800: train loss 1.6609, val loss 1.8137\n",
            "step 4900: train loss 1.6418, val loss 1.8117\n",
            "step 4999: train loss 1.6428, val loss 1.7984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "id": "_bqizhTRt0gg",
        "outputId": "a06ecda6-ae52-4fb1-e43c-a4af2d0775ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BUCKINGHAM:\n",
            "Thou, his lost that thy time grone. I may good fast the dead me the eint.\n",
            "\n",
            "DUKE OR:\n",
            "Not.\n",
            "Citinuon, he lot Gaol Secolm prine,\n",
            "And than those me wound sifens it\n",
            "Lord:\n",
            "Thee hein before in than thy compoun many\n",
            "Where plent: him ere lamor, you nongued\n",
            "He'd down thy madunest some sooth\n",
            "To Engead her me when in\n",
            "Of apponies. Elaked betty, dislives?\n",
            "\n",
            "BRUTUS:\n",
            "I shall thy be of the me.\n",
            "\n",
            "DUKEN ELIZABETH:\n",
            "My lail'd not my oll; so he -the wook,\n",
            "I'll you Godgerer the less not teeds with furth seel\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation of Postional Embedings"
      ],
      "metadata": {
        "id": "siJ7pQGYq_Bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "\n",
        "torch.manual_seed(1337)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-icnVBrBq-U5",
        "outputId": "bc0a99d9-458b-4624-be61-3f474b0e09b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ab7ed1d1350>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "Spx0aIL4rKXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTLanguageModelWithoutPosEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        x = self.blocks(tok_emb) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModelWithoutPosEncoding()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnsRcdgYqaQe",
        "outputId": "161b4abe-f3a7-492b-a5ae-cee40d9701a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.209729 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "mjb2kHU9qysk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On9qoqx7rC-y",
        "outputId": "b5799f43-4b6e-4491-bc8c-2fe18aebce6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.1788, val loss 4.1777\n",
            "step 100: train loss 2.6182, val loss 2.6158\n",
            "step 200: train loss 2.4558, val loss 2.4793\n",
            "step 300: train loss 2.4022, val loss 2.4071\n",
            "step 400: train loss 2.3517, val loss 2.3632\n",
            "step 500: train loss 2.3318, val loss 2.3315\n",
            "step 600: train loss 2.2984, val loss 2.3157\n",
            "step 700: train loss 2.2741, val loss 2.2931\n",
            "step 800: train loss 2.2554, val loss 2.2770\n",
            "step 900: train loss 2.2237, val loss 2.2575\n",
            "step 1000: train loss 2.1884, val loss 2.2262\n",
            "step 1100: train loss 2.1805, val loss 2.2163\n",
            "step 1200: train loss 2.1443, val loss 2.1947\n",
            "step 1300: train loss 2.1265, val loss 2.1756\n",
            "step 1400: train loss 2.1069, val loss 2.1559\n",
            "step 1500: train loss 2.0792, val loss 2.1671\n",
            "step 1600: train loss 2.0845, val loss 2.1422\n",
            "step 1700: train loss 2.0484, val loss 2.1328\n",
            "step 1800: train loss 2.0231, val loss 2.0974\n",
            "step 1900: train loss 2.0050, val loss 2.0845\n",
            "step 2000: train loss 2.0046, val loss 2.0782\n",
            "step 2100: train loss 1.9794, val loss 2.0548\n",
            "step 2200: train loss 1.9656, val loss 2.0464\n",
            "step 2300: train loss 1.9524, val loss 2.0461\n",
            "step 2400: train loss 1.9427, val loss 2.0445\n",
            "step 2500: train loss 1.9236, val loss 2.0181\n",
            "step 2600: train loss 1.9305, val loss 2.0252\n",
            "step 2700: train loss 1.9096, val loss 2.0293\n",
            "step 2800: train loss 1.8780, val loss 2.0071\n",
            "step 2900: train loss 1.8822, val loss 2.0091\n",
            "step 3000: train loss 1.8748, val loss 1.9992\n",
            "step 3100: train loss 1.8571, val loss 2.0003\n",
            "step 3200: train loss 1.8407, val loss 1.9849\n",
            "step 3300: train loss 1.8415, val loss 1.9805\n",
            "step 3400: train loss 1.8408, val loss 1.9746\n",
            "step 3500: train loss 1.8234, val loss 1.9692\n",
            "step 3600: train loss 1.8072, val loss 1.9515\n",
            "step 3700: train loss 1.8112, val loss 1.9485\n",
            "step 3800: train loss 1.7991, val loss 1.9326\n",
            "step 3900: train loss 1.7997, val loss 1.9596\n",
            "step 4000: train loss 1.7961, val loss 1.9436\n",
            "step 4100: train loss 1.7968, val loss 1.9391\n",
            "step 4200: train loss 1.7811, val loss 1.9298\n",
            "step 4300: train loss 1.7735, val loss 1.9341\n",
            "step 4400: train loss 1.7761, val loss 1.9215\n",
            "step 4500: train loss 1.7594, val loss 1.9229\n",
            "step 4600: train loss 1.7457, val loss 1.9088\n",
            "step 4700: train loss 1.7497, val loss 1.9080\n",
            "step 4800: train loss 1.7595, val loss 1.9168\n",
            "step 4900: train loss 1.7350, val loss 1.8852\n",
            "step 4999: train loss 1.7522, val loss 1.8933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlM6SXD1rki8",
        "outputId": "b8987b06-6e75-4631-e8c0-2c6098f84b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Will before whow accking froth\n",
            "Your to obe to take Ond my day hands:\n",
            "Whith full hath buraced?\n",
            "\n",
            "Doates will my fachsance zonoun\n",
            "Yours, tof it heart milend;\n",
            "Whate misters, acin latest in overs, and Warrwewick you son leling tear.\n",
            "\n",
            "KING RICHARY:\n",
            "Supp ais's lety mour made.\n",
            "By pater to whom\n",
            "Glow, to that\n",
            "mont not when evily o' a moscerious gentleed to-o more for unto a my cruptef so;\n",
            "Angr to shall is all one to farse?\n",
            "\n",
            "KING HErefurse, courdddes:\n",
            "Saday With Earth, hoph cour acraney it-lip chan you!\n",
            "\n",
            "J\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hardcoding the pos elements(sinusoidal)"
      ],
      "metadata": {
        "id": "cPDDU0Xks5AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 5\n",
        "n_embd = 3\n",
        "\n",
        "pe = torch.zeros(block_size, n_embd)\n",
        "for pos in range(block_size):\n",
        "    for i in range(0, n_embd, 2):\n",
        "        pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/n_embd)))\n",
        "        if i + 1 < n_embd:\n",
        "            pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * i)/n_embd)))\n",
        "\n",
        "print(pe)"
      ],
      "metadata": {
        "id": "quaR8VB7tLvV",
        "outputId": "a79b6e0d-154d-45c2-a454-4524c5a7bb7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00],\n",
            "        [ 8.4147e-01,  5.4030e-01,  4.6416e-06],\n",
            "        [ 9.0930e-01, -4.1615e-01,  9.2832e-06],\n",
            "        [ 1.4112e-01, -9.8999e-01,  1.3925e-05],\n",
            "        [-7.5680e-01, -6.5364e-01,  1.8566e-05]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class GPTLanguageModelWithoutPosEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        pe = torch.zeros(block_size, n_embd)\n",
        "        for pos in range(block_size):\n",
        "            for i in range(0, n_embd, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/n_embd)))\n",
        "                if i + 1 < n_embd:\n",
        "                    pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * i)/n_embd)))\n",
        "        self.register_buffer(\"positional_encoding\", pe)\n",
        "\n",
        "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_emb = self.positional_encoding[:T]     # (T, C)\n",
        "        x = tok_emb + pos_emb                      # (B, T, C)\n",
        "        x = self.blocks(tok_emb) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModelWithoutPosEncoding()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "id": "oyip2mjYs4hR",
        "outputId": "e80191e7-3be6-4f2a-dff0-d21fe6d57d9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.207681 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "ur0QJMRYs9cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "51qzBT-as_eQ",
        "outputId": "b6e0a4e5-59bf-44ca-bc1a-06fd60285e8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.1634, val loss 4.1645\n",
            "step 100: train loss 2.5903, val loss 2.5886\n",
            "step 200: train loss 2.4678, val loss 2.4825\n",
            "step 300: train loss 2.4178, val loss 2.4189\n",
            "step 400: train loss 2.3597, val loss 2.3641\n",
            "step 500: train loss 2.3223, val loss 2.3363\n",
            "step 600: train loss 2.2882, val loss 2.2930\n",
            "step 700: train loss 2.2603, val loss 2.3000\n",
            "step 800: train loss 2.2500, val loss 2.2769\n",
            "step 900: train loss 2.2185, val loss 2.2525\n",
            "step 1000: train loss 2.2029, val loss 2.2289\n",
            "step 1100: train loss 2.1795, val loss 2.1950\n",
            "step 1200: train loss 2.1549, val loss 2.1902\n",
            "step 1300: train loss 2.1333, val loss 2.1736\n",
            "step 1400: train loss 2.1131, val loss 2.1593\n",
            "step 1500: train loss 2.0893, val loss 2.1297\n",
            "step 1600: train loss 2.0653, val loss 2.1269\n",
            "step 1700: train loss 2.0276, val loss 2.1047\n",
            "step 1800: train loss 2.0270, val loss 2.1176\n",
            "step 1900: train loss 2.0201, val loss 2.0964\n",
            "step 2000: train loss 2.0031, val loss 2.0835\n",
            "step 2100: train loss 2.0013, val loss 2.0883\n",
            "step 2200: train loss 1.9700, val loss 2.0606\n",
            "step 2300: train loss 1.9528, val loss 2.0400\n",
            "step 2400: train loss 1.9360, val loss 2.0373\n",
            "step 2500: train loss 1.9345, val loss 2.0355\n",
            "step 2600: train loss 1.9127, val loss 2.0278\n",
            "step 2700: train loss 1.9067, val loss 2.0215\n",
            "step 2800: train loss 1.9027, val loss 2.0017\n",
            "step 2900: train loss 1.9002, val loss 2.0047\n",
            "step 3000: train loss 1.8852, val loss 1.9994\n",
            "step 3100: train loss 1.8780, val loss 1.9967\n",
            "step 3200: train loss 1.8631, val loss 1.9983\n",
            "step 3300: train loss 1.8572, val loss 1.9824\n",
            "step 3400: train loss 1.8491, val loss 1.9758\n",
            "step 3500: train loss 1.8379, val loss 1.9793\n",
            "step 3600: train loss 1.8232, val loss 1.9754\n",
            "step 3700: train loss 1.8281, val loss 1.9808\n",
            "step 3800: train loss 1.8163, val loss 1.9545\n",
            "step 3900: train loss 1.8086, val loss 1.9647\n",
            "step 4000: train loss 1.8148, val loss 1.9756\n",
            "step 4100: train loss 1.8110, val loss 1.9575\n",
            "step 4200: train loss 1.8025, val loss 1.9335\n",
            "step 4300: train loss 1.7961, val loss 1.9438\n",
            "step 4400: train loss 1.7844, val loss 1.9470\n",
            "step 4500: train loss 1.7840, val loss 1.9447\n",
            "step 4600: train loss 1.7840, val loss 1.9441\n",
            "step 4700: train loss 1.7746, val loss 1.9195\n",
            "step 4800: train loss 1.7802, val loss 1.9344\n",
            "step 4900: train loss 1.7705, val loss 1.9130\n",
            "step 4999: train loss 1.7810, val loss 1.9354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "id": "o7-22gkctAo3",
        "outputId": "dcaf8c92-7ee0-4dd2-f92b-9af8700b3a19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MONE:\n",
            "Froke mary.\n",
            "\n",
            "HENRRY BROLImes BRD:Those.--'Somes the me madany shows;\n",
            "Will what we bear, whom counfe: I should sol.\n",
            "\n",
            "AnEOSTABRT:\n",
            "Tear, thou earte beher very imdis?\n",
            "\n",
            "LADY:\n",
            "And mee?\n",
            "You;\n",
            "\n",
            "PROPEY Andord evertal ny, come, overes night,\n",
            "All, I deeepox the have bagakes against's\n",
            "Awway k sleve buelow; and stoneld not no dearcks\n",
            "Lors, hilde in himpser's in now this mee thee?\n",
            "\n",
            "CLARGENteorn, Thee subgn Clicktanon what than the build Edwllembke, on sold;\n",
            "For for claw thine. You there farc;\n",
            "you comes. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoPE\n",
        "- relative position encoding\n",
        "- example the cat sat on....\n",
        "- the model is processing the token at position 4: the\n",
        "- the model looks back at the previous tokens:\n",
        "  - on at pos 3 | relative position -1\n",
        "  - sat at pos 2 | relative position -2\n",
        "  - cat at pos 1 | relative position -3\n",
        "  - the at post 0 | relative position -4\n",
        "\n",
        "# absolute positions\n",
        "- each token at index i gets position embedding PE[i]\n",
        "- dot(Wq * (x_i + PE[i]), Wk * (x_j + PE[j]))\n",
        "- attention score depnds on i and j separately\n",
        "\n",
        "# RoPE:\n",
        "- The vectors x_i and x_j are rotated according to position.\n",
        "- q = rotate(Wq * x_i, θ * i)\n",
        "- k = rotate(Wk * x_j, θ * j)\n",
        "- score = q @ k\n",
        "- rotation causes: score ∝ cos(θ * (i - j))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DTMNlfYqERB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_rope(q, k):\n",
        "    # q, k: (B, T, C), where C must be even\n",
        "    B, T, C = q.shape\n",
        "    half = C // 2\n",
        "    freqs = torch.exp(-torch.arange(0, half, dtype=torch.float32) * math.log(10000) / half).to(q.device)  # (half,)\n",
        "    positions = torch.arange(T, device=q.device).float()  # (T,)\n",
        "    angles = torch.einsum('t,d->td', positions, freqs)  # (T, half)\n",
        "    sin = angles.sin().unsqueeze(0)  # (1, T, half)\n",
        "    cos = angles.cos().unsqueeze(0)  # (1, T, half)\n",
        "\n",
        "    q1, q2 = q[..., :half], q[..., half:]\n",
        "    k1, k2 = k[..., :half], k[..., half:]\n",
        "    q_rotated = torch.cat([q1 * cos - q2 * sin, q1 * sin + q2 * cos], dim=-1)\n",
        "    k_rotated = torch.cat([k1 * cos - k2 * sin, k1 * sin + k2 * cos], dim=-1)\n",
        "    return q_rotated, k_rotated"
      ],
      "metadata": {
        "id": "SDs80upZoHsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "\n",
        "        # 🌀 Apply RoPE here!\n",
        "        q, k = apply_rope(q, k)\n",
        "\n",
        "        wei = q @ k.transpose(-2, -1) * (C ** -0.5)  # (B,T,T)\n",
        "        wei = wei.masked_fill(torch.tril(torch.ones(T, T, device=x.device)) == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        v = self.value(x)  # (B,T,hs)\n",
        "        out = wei @ v      # (B,T,hs)\n",
        "        return out"
      ],
      "metadata": {
        "id": "HaO5o7WXjkBi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTLanguageModelRoPE(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        x = self.blocks(tok_emb) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModelRoPE()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpNM3BhgjjRH",
        "outputId": "2be79bef-140b-4898-b30e-4aea1fe2a92a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.207681 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "mawnqqTYkMzA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFpTvH9ukWON",
        "outputId": "5667f8fa-7745-4e55-8d4f-c032dfa68f5b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.2143, val loss 4.2171\n",
            "step 100: train loss 2.5749, val loss 2.5743\n",
            "step 200: train loss 2.4001, val loss 2.4026\n",
            "step 300: train loss 2.2972, val loss 2.3093\n",
            "step 400: train loss 2.2002, val loss 2.2044\n",
            "step 500: train loss 2.1168, val loss 2.1433\n",
            "step 600: train loss 2.0700, val loss 2.1063\n",
            "step 700: train loss 2.0148, val loss 2.0701\n",
            "step 800: train loss 1.9726, val loss 2.0354\n",
            "step 900: train loss 1.9355, val loss 2.0070\n",
            "step 1000: train loss 1.9239, val loss 1.9884\n",
            "step 1100: train loss 1.8795, val loss 1.9821\n",
            "step 1200: train loss 1.8695, val loss 1.9592\n",
            "step 1300: train loss 1.8465, val loss 1.9666\n",
            "step 1400: train loss 1.8244, val loss 1.9342\n",
            "step 1500: train loss 1.7966, val loss 1.9228\n",
            "step 1600: train loss 1.7900, val loss 1.9188\n",
            "step 1700: train loss 1.7787, val loss 1.9156\n",
            "step 1800: train loss 1.7778, val loss 1.9023\n",
            "step 1900: train loss 1.7533, val loss 1.8923\n",
            "step 2000: train loss 1.7425, val loss 1.8898\n",
            "step 2100: train loss 1.7401, val loss 1.9000\n",
            "step 2200: train loss 1.7217, val loss 1.8771\n",
            "step 2300: train loss 1.7038, val loss 1.8702\n",
            "step 2400: train loss 1.7196, val loss 1.8571\n",
            "step 2500: train loss 1.6983, val loss 1.8690\n",
            "step 2600: train loss 1.6803, val loss 1.8644\n",
            "step 2700: train loss 1.6967, val loss 1.8470\n",
            "step 2800: train loss 1.6781, val loss 1.8256\n",
            "step 2900: train loss 1.6773, val loss 1.8400\n",
            "step 3000: train loss 1.6641, val loss 1.8256\n",
            "step 3100: train loss 1.6615, val loss 1.8300\n",
            "step 3200: train loss 1.6431, val loss 1.8093\n",
            "step 3300: train loss 1.6446, val loss 1.8260\n",
            "step 3400: train loss 1.6388, val loss 1.8218\n",
            "step 3500: train loss 1.6453, val loss 1.8015\n",
            "step 3600: train loss 1.6397, val loss 1.7981\n",
            "step 3700: train loss 1.6393, val loss 1.8023\n",
            "step 3800: train loss 1.6313, val loss 1.7879\n",
            "step 3900: train loss 1.6338, val loss 1.8036\n",
            "step 4000: train loss 1.6231, val loss 1.7961\n",
            "step 4100: train loss 1.6110, val loss 1.7819\n",
            "step 4200: train loss 1.6126, val loss 1.7788\n",
            "step 4300: train loss 1.6090, val loss 1.7838\n",
            "step 4400: train loss 1.6153, val loss 1.7832\n",
            "step 4500: train loss 1.5971, val loss 1.7950\n",
            "step 4600: train loss 1.6061, val loss 1.7973\n",
            "step 4700: train loss 1.5962, val loss 1.7914\n",
            "step 4800: train loss 1.6067, val loss 1.7835\n",
            "step 4900: train loss 1.6019, val loss 1.7861\n",
            "step 4999: train loss 1.5891, val loss 1.7664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i0S3JNZkSH7",
        "outputId": "a8aec445-fbbe-4659-ad80-691eb2fddabf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "And they bridl'd and is by be mades;\n",
            "Thou but take Onation agaidess: 'tis he usquich\n",
            "At are that ane away, my facher,\n",
            "And I'll now, Ladom was I coveriand;\n",
            "Whices is eye, I in latiumain overs, and Warwick on you mustleling peace thus, once by stay; and plaw you:\n",
            "That I croopes, and whom\n",
            "Is would that\n",
            "To Windon him eiills the most rive with impusion,\n",
            "Ke show butter danger, the son; if his shall I male oftence, Privant, or, and bubb!\n",
            "\n",
            "QUEEN KING HENRY VI:\n",
            "Whereforious trayard, your his coff you!\n",
            "My\n"
          ]
        }
      ]
    }
  ]
}