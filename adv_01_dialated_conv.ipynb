{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjDX6SNvKTv8Xryfnikdln",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominiksakic/zero_to_hero/blob/main/adv_01_dialated_conv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Goal\n",
        "- implement a dialated Convolutions\n",
        "- link: https://arxiv.org/pdf/1609.03499"
      ],
      "metadata": {
        "id": "f_UfT-VrLDuA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEqQm8txKY_G",
        "outputId": "fffc7196-bfbb-4891-d742-8a7c74c70f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-10 12:17:32--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "names.txt           100%[===================>] 222.80K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2025-07-10 12:17:32 (42.0 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#BOILERPLATE CONVNET\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "DASrFOJXLUpi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "\n",
        "# build vocab and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i : s for s, i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "\n",
        "\n",
        "# build the dataset\n",
        "block_size = 8\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "  for w in words:\n",
        "\n",
        "    #print(w)\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcfToNjILXB9",
        "outputId": "d5370701-9356-4e58-b373-1c344db4eb86"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "torch.Size([182625, 8]) torch.Size([182625])\n",
            "torch.Size([22655, 8]) torch.Size([22655])\n",
            "torch.Size([22866, 8]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingWithReshape(nn.Module):\n",
        "  def __init__(self, vocab_size, n_embd):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, n_embd)\n",
        "  \"\"\"\n",
        "  Use transpose to rearrange dimensions.\n",
        "  View wont work unless the tensor is already in the correct memory layout.\n",
        "  Usefull link: https://blog.ezyang.com/2019/05/pytorch-internals/\n",
        "  \"\"\"\n",
        "  def forward(self, x):\n",
        "    # x: (B, T)\n",
        "    x = self.embedding(x) # (B,T,C)\n",
        "    x = x.transpose(1, 2) # (B,C,T)\n",
        "    return x"
      ],
      "metadata": {
        "id": "vN-J4bkPLZz5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10\n",
        "n_hidden = 20\n",
        "block_size = 8\n",
        "\n",
        "model = nn.Sequential(\n",
        "    EmbeddingWithReshape(vocab_size, n_embd),\n",
        "    nn.Conv1d(n_embd, n_hidden, kernel_size=2),\n",
        "    nn.BatchNorm1d(n_hidden),\n",
        "    nn.Tanh(),\n",
        "\n",
        "    nn.Conv1d(n_hidden, n_hidden, kernel_size=2),\n",
        "    nn.BatchNorm1d(n_hidden),\n",
        "    nn.Tanh(),\n",
        "\n",
        "    nn.Conv1d(n_hidden, n_hidden, kernel_size=2),\n",
        "    nn.BatchNorm1d(n_hidden),\n",
        "    nn.Tanh(),\n",
        "\n",
        "    nn.AdaptiveAvgPool1d(1),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(n_hidden, vocab_size),\n",
        ")\n",
        "\n",
        "x = torch.randint(0, vocab_size, (32, block_size))\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "\n",
        "for layer in model:\n",
        "    x = layer(x)\n",
        "    print(f\"{layer.__class__.__name__}: {x.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LscO4_sJLqwj",
        "outputId": "eda68564-40ae-42a0-c765-a8c233be1a89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([32, 8])\n",
            "EmbeddingWithReshape: torch.Size([32, 10, 8])\n",
            "Conv1d: torch.Size([32, 20, 7])\n",
            "BatchNorm1d: torch.Size([32, 20, 7])\n",
            "Tanh: torch.Size([32, 20, 7])\n",
            "Conv1d: torch.Size([32, 20, 6])\n",
            "BatchNorm1d: torch.Size([32, 20, 6])\n",
            "Tanh: torch.Size([32, 20, 6])\n",
            "Conv1d: torch.Size([32, 20, 5])\n",
            "BatchNorm1d: torch.Size([32, 20, 5])\n",
            "Tanh: torch.Size([32, 20, 5])\n",
            "AdaptiveAvgPool1d: torch.Size([32, 20, 1])\n",
            "Flatten: torch.Size([32, 20])\n",
            "Linear: torch.Size([32, 27])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = list(model.parameters())\n",
        "print(f\"Parameters: {sum((p.nelement() for p in parameters))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkOJw0QBLsGi",
        "outputId": "92bad905-3a01-4d65-e1cc-7c56f4a2ce8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: 3017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "ud = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "  # forward pass\n",
        "  logits = model(Xb)\n",
        "  loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  lr = 0.1 if i < 150000 else 0.01\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0:\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnJBatS_LupQ",
        "outputId": "810d6be2-7c00-4ced-85b9-ed748de02fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/ 200000: 3.3641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BOILERPLATE END"
      ],
      "metadata": {
        "id": "mceiE_GfL1DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is a dialted Convolution?\n",
        "- A dialted convolution introduces gaps between kernel elements. In 1D, this means the filter covers a wider range of input elements without increasing the number of parameters.\n",
        "\n",
        "- main idea: each layer covers a sparse pattern, but the full network sees a dense pattern\n",
        "\n",
        "# Kernel Example\n",
        "  - Input : x0 x1 x2 x3 x4 x5 x6\n",
        "  - Conv-k : x0 x1 x2\n",
        "  - dConv-k: x0    x2    x4\n",
        "\n",
        "# Layer example\n",
        "## Model L0 d=1 -> L1 d=2 -> L2 d=4\n",
        "\n",
        "- Standard convolution/Dialation 1\n",
        "- [x0, x1, x2] → y0\n",
        "- [x1, x2, x3] → y1\n",
        "- [x2, x3, x4] → y2\n",
        "- [x3, x4, x5] → y3\n",
        "- [x4, x5, x6] → y4\n",
        "\n",
        "- Dialation = 2\n",
        "- [x0,   x2,   x4] → z0\n",
        "- [x1,   x3,   x5] → z1\n",
        "- [x2,   x4,   x6] → z2\n",
        "\n",
        "- Dialation = 4\n",
        "- [x0, x4, --] → w0\n",
        "- [x1, x5, --] → w1\n",
        "\n",
        "# Summary of Coverage\n",
        "- x0   | L0, L1, L2\n",
        "- x1   | L0, L1, L2\n",
        "- x2   | L0, L1\n",
        "- x3   | L0, L1\n",
        "- x4   | L0, L1, L2\n",
        "- x5   | L0, L1, L2\n",
        "- x6   | L0, L1\n",
        "\n",
        "- --> Dialted convolutions skip information, but stacking them with increasing dialation lets the network:\n",
        "  - Cover all inputs\n",
        "  - See both local nad global context\n",
        "  - grow the receptive field exponentially"
      ],
      "metadata": {
        "id": "rPzSMpRjQW0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The gensis of Dialted Convolution\n",
        "- Goal is to build it up from toy examples, to understand it all.\n",
        "\n"
      ],
      "metadata": {
        "id": "9oGMjceQK2xD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([0., 1., 2., 3., 4., 5., 6.])\n",
        "kernel = torch.tensor([1., 10., 100.])\n",
        "\n",
        "output = []\n",
        "\n",
        "for t in range(x.shape[0] - kernel.shape[0] + 1):  # (T - K + 1)\n",
        "    window = x[t:t+3]\n",
        "    conv = (window * kernel).sum()\n",
        "    output.append(conv.item())\n",
        "\n",
        "# Problem output shrink\n",
        "print(\"Standard convolution output:\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "ZLz2qIHvLEgm",
        "outputId": "1f1d781e-db2f-45de-d470-f6470bbdbba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard convolution output:\n",
            "[210.0, 321.0, 432.0, 543.0, 654.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dilation = 2\n",
        "output = []\n",
        "\n",
        "for t in range(x.shape[0] - dilation*2):\n",
        "  i0 = t\n",
        "  i1 = t + dilation\n",
        "  i2 = t + 2*dilation\n",
        "  window = torch.stack([x[i0], x[i1], x[i2]])\n",
        "  conv = (window * kernel).sum()\n",
        "  output.append(conv.item())\n",
        "\n",
        "print(\"\\nDilated convolution (d=2) output:\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "-T0bApHxLYh5",
        "outputId": "0df432d4-3ada-4a2b-e3d8-2a8b20d29bd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dilated convolution (d=2) output:\n",
            "[420.0, 531.0, 642.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0., 1., 2., 3., 4., 5., 6.])\n",
        "kernel = torch.tensor([1., 10., 100.])\n",
        "\n",
        "def dilated_conv_1d_same(x, kernel, dilation):\n",
        "    K = kernel.shape[0]\n",
        "    pad = dilation * ((K - 1) // 2)\n",
        "    x_padded = torch.nn.functional.pad(x, (pad, pad))\n",
        "\n",
        "    output = []\n",
        "\n",
        "    for t in range(x.shape[0]):\n",
        "        i0 = t\n",
        "        i1 = t + dilation\n",
        "        i2 = t + 2 * dilation\n",
        "        if i2 >= x_padded.shape[0]:\n",
        "            break  # prevent out-of-bounds\n",
        "        window = torch.stack([\n",
        "            x_padded[i0],\n",
        "            x_padded[i1],\n",
        "            x_padded[i2],\n",
        "        ])\n",
        "        conv = (window * kernel).sum()\n",
        "        output.append(conv.item())\n",
        "    return torch.tensor(output)\n",
        "\n",
        "# Layer 0: dilation=1\n",
        "y0 = dilated_conv_1d_same(x, kernel, dilation=1)\n",
        "print(f\"L0 (d=1): {y0}\")\n",
        "print(f\"L0 element: {y0.shape}\")\n",
        "\n",
        "# Layer 1: dilation=2\n",
        "y1 = dilated_conv_1d_same(y0, kernel, dilation=2)\n",
        "print(f\"L1 (d=2): {y1}\")\n",
        "print(f\"L1 element: {y1.shape}\")\n",
        "\n",
        "# Layer 2: dilation=4\n",
        "y2 = dilated_conv_1d_same(y1, kernel, dilation=4)\n",
        "print(f\"L2 (d=4): {y2}\")\n",
        "print(f\"L2 element: {y2.shape}\")\n"
      ],
      "metadata": {
        "id": "oPGLsjHyOrv7",
        "outputId": "fb96805a-d0ac-4e58-f093-ee4cdf159f42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L0 (d=1): tensor([100., 210., 321., 432., 543., 654.,  65.])\n",
            "L0 element: torch.Size([7])\n",
            "L1 (d=2): tensor([33100., 45300., 57610., 69930., 12251.,  6972.,  1193.])\n",
            "L1 element: torch.Size([7])\n",
            "L2 (d=4): tensor([1556100., 1150200.,  695400.,  699300.,  155610.,  115020.,   69540.])\n",
            "L2 element: torch.Size([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytroch implementation\n",
        "class DialatedConvolution(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
        "    super().__init__()\n",
        "    self.kernel_size = kernel_size\n",
        "    self.padding = dilation * (kernel_size - 1)\n",
        "    self.conv = nn.Conv1d(\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        dilation=dilation\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Pad left side only.\n",
        "    x = F.pad(x, (self.padding, 0))\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "b--ThpE3z6E-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10\n",
        "n_hidden = 100\n",
        "block_size = 8\n",
        "\n",
        "model = nn.Sequential(\n",
        "    EmbeddingWithReshape(vocab_size, n_embd),\n",
        "    DialatedConvolution(n_embd, n_hidden, kernel_size=2, dilation=1),\n",
        "    nn.BatchNorm1d(n_hidden),\n",
        "    nn.Tanh(),\n",
        "\n",
        "    DialatedConvolution(n_hidden, n_hidden, kernel_size=2, dilation=2),\n",
        "    nn.BatchNorm1d(n_hidden),\n",
        "    nn.Tanh(),\n",
        "\n",
        "    DialatedConvolution(n_hidden, n_hidden, kernel_size=2, dilation=4),\n",
        "    nn.BatchNorm1d(n_hidden),\n",
        "    nn.Tanh(),\n",
        "\n",
        "    nn.AdaptiveAvgPool1d(1),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(n_hidden, vocab_size),\n",
        ")\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "8nwv__422Sxo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = list(model.parameters())\n",
        "print(f\"Parameters: {sum((p.nelement() for p in parameters))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOJ4auWI33XS",
        "outputId": "f48f435c-530f-4e2e-ff9d-2f467cf0aea6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: 45897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding accuracy\n",
        "### What is Accuracy?\n",
        "1. Take the logits\n",
        "2. convert them into predicted class: argmax(dim=1)\n",
        "3. Compare those to the true labels (preds == targets)\n",
        "4. Count how many were correct, and divide by batch size."
      ],
      "metadata": {
        "id": "DUcpjwZ5VKpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_loss(split):\n",
        "  model.eval()\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "\n",
        "  with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    logits = model(x)\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    acc = (preds == y).float().mean()\n",
        "  return loss, acc"
      ],
      "metadata": {
        "id": "uTMU0K8D4LOH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "tr_loss_his, dev_loss_his = [], []\n",
        "tr_acc_his, dev_acc_his = [], []\n",
        "\n",
        "for i in range(max_steps):\n",
        "  model.train()\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "  Xb, Yb = Xtr[ix].to(device), Ytr[ix].to(device)\n",
        "\n",
        "  # forward pass\n",
        "  logits = model(Xb)\n",
        "  train_loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "  # accuracy\n",
        "  preds = torch.argmax(logits, dim=1)\n",
        "  train_acc = (preds == Yb).float().mean()\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "\n",
        "  train_loss.backward()\n",
        "\n",
        "  # update\n",
        "  lr = 0.1 if i < 150000 else 0.01\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  with torch.no_grad():\n",
        "    dev_loss, dev_acc = split_loss('val')\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0:\n",
        "    print(f'{i:7d}/{max_steps:7d} - Train loss: {train_loss.item():.4f} Acc: {train_acc:.4f} | Val loss: {dev_loss.item():.4f} Acc: {dev_acc:.4f}')\n",
        "\n",
        "  tr_loss_his.append(train_loss.log10().item())\n",
        "  dev_loss_his.append(dev_loss.log10().item())\n",
        "  tr_acc_his.append(train_acc.log10().item())\n",
        "  dev_acc_his.append(dev_acc.log10().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYNIDrNy34Ig",
        "outputId": "5b51f7c1-0c21-423e-e845-17f8cf8775d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/ 200000 - Train loss: 3.2851 Acc: 0.0625 | Val loss: 3.3051 Acc: 0.0433\n",
            "  10000/ 200000 - Train loss: 2.3048 Acc: 0.3125 | Val loss: 2.2942 Acc: 0.3004\n",
            "  20000/ 200000 - Train loss: 2.2601 Acc: 0.2812 | Val loss: 2.2218 Acc: 0.3154\n",
            "  30000/ 200000 - Train loss: 2.0260 Acc: 0.4375 | Val loss: 2.1485 Acc: 0.3359\n",
            "  40000/ 200000 - Train loss: 1.5560 Acc: 0.5312 | Val loss: 2.1278 Acc: 0.3446\n",
            "  50000/ 200000 - Train loss: 1.7910 Acc: 0.4375 | Val loss: 2.1000 Acc: 0.3476\n",
            "  60000/ 200000 - Train loss: 1.8856 Acc: 0.2812 | Val loss: 2.1213 Acc: 0.3433\n",
            "  70000/ 200000 - Train loss: 1.7419 Acc: 0.4375 | Val loss: 2.0878 Acc: 0.3520\n",
            "  80000/ 200000 - Train loss: 2.1320 Acc: 0.4375 | Val loss: 2.0864 Acc: 0.3547\n",
            "  90000/ 200000 - Train loss: 2.0916 Acc: 0.3125 | Val loss: 2.0787 Acc: 0.3492\n",
            " 100000/ 200000 - Train loss: 2.0435 Acc: 0.3438 | Val loss: 2.0755 Acc: 0.3523\n",
            " 110000/ 200000 - Train loss: 1.8939 Acc: 0.4688 | Val loss: 2.0803 Acc: 0.3542\n",
            " 120000/ 200000 - Train loss: 2.1086 Acc: 0.3750 | Val loss: 2.0668 Acc: 0.3544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to tensors\n",
        "tr_loss_t = torch.tensor(tr_loss_his)\n",
        "dev_loss_t = torch.tensor(dev_loss_his)\n",
        "tr_acc_t  = torch.tensor(tr_acc_his)\n",
        "dev_acc_t = torch.tensor(dev_acc_his)"
      ],
      "metadata": {
        "id": "EbK9Mdrw4OTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk = 1000\n",
        "tr_loss_smooth = tr_loss_t.view(-1, chunk).mean(1)\n",
        "dev_loss_smooth = dev_loss_t.view(-1, chunk).mean(1)\n",
        "tr_acc_smooth = tr_acc_t.view(-1, chunk).mean(1)\n",
        "dev_acc_smooth = dev_acc_t.view(-1, chunk).mean(1)\n",
        "\n",
        "# plot\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(tr_loss_smooth, label='train')\n",
        "plt.plot(dev_loss_smooth, label='val')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Thousands of steps')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(tr_acc_smooth, label='train')\n",
        "plt.plot(dev_acc_smooth, label='val')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Thousands of steps')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VHABLFqpYHFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size\n",
        "    context = torch.tensor([context], dtype=torch.long).to(device)\n",
        "    while True:\n",
        "      logits = model(context)\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      # sample from the distribution\n",
        "      ix = torch.multinomial(probs, num_samples=1).item()\n",
        "      out.append(ix)\n",
        "      # shift the context window and track the samples\n",
        "      context = torch.cat([context[:, 1:], torch.tensor([[ix]], device=device)], dim=1)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4dFuXhI4PFM",
        "outputId": "a4694d4e-711c-46d6-ce61-5acfb89d1c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "navyah.\n",
            "mattison.\n",
            "naevia.\n",
            "seisa.\n",
            "aitanya.\n",
            "delynn.\n",
            "breyann.\n",
            "aulree.\n",
            "codee.\n",
            "dwade.\n",
            "nyel.\n",
            "rizce.\n",
            "krisha.\n",
            "aaliyah.\n",
            "bin.\n",
            "aleh.\n",
            "khyler.\n",
            "dallys.\n",
            "bejaliu.\n",
            "nylia.\n"
          ]
        }
      ]
    }
  ]
}