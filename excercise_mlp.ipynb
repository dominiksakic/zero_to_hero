{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDMSCfYLk8i68WGvmmzzCH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominiksakic/zero_to_hero/blob/main/excercise_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Papers\n",
        "https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf\n",
        "\n",
        "# Exercises:\n",
        "- E01: Tune the hyperparameters of the training to beat best validation loss of 2.2 (COMPLETE!)\n",
        "  - Increase block_size\n",
        "  - Increase size of Lookup table.\n",
        "  - Increase hidden layer.\n",
        "  - Length of the training\n",
        "  - Learning rate\n",
        "  - Batch size for convergence speed\n",
        "- E02:\n",
        "  - (1) What is the loss you'd get if the predicted probabilities at initialization were perfectly uniform? What loss do we achieve? --> Initialize the C matrix to ones, instead of random nums, and I would expect the loss to be 27! Because each char would be the same 1/27 out come. (COMPLETE! )\n",
        "  - (2) Can you tune the initialization to get a starting loss that is much more similar to (1)? --> Initialize all parameters to 1. Loss is 3.2. Intution of 1 was wrong. Real reason of the Loss being 3.2 after having auniform distribution is that the last tensor is 200 streched out 27 times. Crossentropy: -log(1/27) = log(27) ~ 3.2.. (COMPLETE!)\n",
        "- E03: Read the Bengio et al 2003 paper (link above), implement and try any idea from the paper. Did it work?"
      ],
      "metadata": {
        "id": "i1Jk2v3vVY-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the names.txt file from github\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig7PRcQXHDk7",
        "outputId": "a9ba2d0e-d0cb-447c-c2ec-7708cf51c6ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-22 01:31:54--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "\rnames.txt             0%[                    ]       0  --.-KB/s               \rnames.txt           100%[===================>] 222.80K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-06-22 01:31:54 (6.04 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "766AYozfHCeu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()"
      ],
      "metadata": {
        "id": "yvL4_SDDHFi4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocab and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i : s for s, i in stoi.items()}"
      ],
      "metadata": {
        "id": "Ojn8yDDSHX0D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 4\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "  for w in words:\n",
        "\n",
        "    #print(w)\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZoq69stH_4C",
        "outputId": "53c6b9a5-bd7c-49a1-fb55-4cc68fbce39e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 4]) torch.Size([182625])\n",
            "torch.Size([22655, 4]) torch.Size([22655])\n",
            "torch.Size([22866, 4]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.ones((27, 20))\n",
        "W1 = torch.ones((80, 200))\n",
        "b1 = torch.ones(200)\n",
        "W2 = torch.ones((200, 27))\n",
        "b2 = torch.ones(27)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "OisNKgGaKgH6"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hidden layer size:\n",
        "- 500 -> worse\n",
        "- 300 -> worse\n",
        "- 200 -> best so far\n",
        "---\n",
        "- Lookup table double -> dev set improve\n",
        "---\n",
        "- double the training length-> No improvement\n",
        "---\n",
        "- shorten train len to 10000, and increase batch size: 64 - no improvement.\n",
        "- batch size: 128 - no improvement\n",
        "- higher batch and longer training better\n",
        "---\n",
        "- increase block size improved perfromance on dev set."
      ],
      "metadata": {
        "id": "7u1htTFFLyps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # number of parameters in total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX5vjH5XOdsX",
        "outputId": "084d41b8-5ffe-4ef8-d9a6-1b3e837c1bbc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22167"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "TNpCSVTnOf1H"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lri = []\n",
        "lossi = []\n",
        "stepi = []"
      ],
      "metadata": {
        "id": "k2g4AN2_PCAn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(200000):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (128,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (128, 4, 20)\n",
        "  h = torch.tanh(emb.view(-1, 80) @ W1 + b1) # (128, 200)\n",
        "  logits = h @ W2 + b2 # (128, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "  if i == 0:\n",
        "    print(f'Initial loss: {loss}')\n",
        "    break\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  #lr = lrs[i]\n",
        "  lr = 0.1 if i < 100000 else 0.01\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats, lri for finding a good lr\n",
        "  #lri.append(lre[i])\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "JuqZxgv0NjjE",
        "outputId": "c441cb68-649d-4a53-c5e7-fa841560acc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss: 3.295837163925171\n",
            "3.295837163925171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(stepi, lossi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "Pg3kEiwfPDSn",
        "outputId": "0b596924-cd12-43f7-9e56-c87ecfd1358c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x79d063217650>]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(X, Y):\n",
        "  emb = C[X]\n",
        "  h = torch.tanh(emb.view(-1, 80) @ W1 + b1)\n",
        "  logits = h @ W2 + b2\n",
        "  loss = F.cross_entropy(logits, Y)\n",
        "  return loss.item()"
      ],
      "metadata": {
        "id": "GCeEnoYfQBTo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loss\n",
        "train_loss = calculate_loss(Xtr, Ytr)\n",
        "train_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1qKgqfgP29s",
        "outputId": "4470bf37-8c0c-4829-ecae-68131097c6e9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8309552669525146"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation loss\n",
        "dev_loss = calculate_loss(Xdev, Ydev)\n",
        "dev_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8149kxg-P4jL",
        "outputId": "bc21c63b-32d8-431c-ab15-a045afb80a2d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.828760862350464"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test loss\n",
        "test_loss = calculate_loss(Xte, Yte)\n",
        "test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUHhjbhoP50H",
        "outputId": "9e173b23-2ea0-4011-9bb9-c1dd2d825283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1083648204803467"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
        "      logits = h @ W2 + b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdmcOUSqQxJt",
        "outputId": "cad2de03-07d4-4602-a8c7-08390c562b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mora.\n",
            "mayah.\n",
            "seelen.\n",
            "hayla.\n",
            "reiman.\n",
            "endrie.\n",
            "caileed.\n",
            "eliiah.\n",
            "poren.\n",
            "edeineana.\n",
            "arlely.\n",
            "kohlara.\n",
            "noshien.\n",
            "gihiman.\n",
            "trintoniel.\n",
            "panter.\n",
            "foun.\n",
            "kynder.\n",
            "yarley.\n",
            "kaylah.\n"
          ]
        }
      ]
    }
  ]
}