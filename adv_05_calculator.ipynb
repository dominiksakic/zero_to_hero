{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzhnKkX0VxbV5CVio+7add",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominiksakic/zero_to_hero/blob/main/adv_05_calculator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Goal\n",
        "Train a GPT to do addition of two numbers, i.e. a+b=c. You may find it helpful to predict the digits of c in reverse order, as the typical addition algorithm (that you're hoping it learns) would proceed right to left too. You may want to modify the data loader to simply serve random problems and skip the generation of train.bin, val.bin. You may want to mask out the loss at the input positions of a+b that just specify the problem using y=-1 in the targets (see CrossEntropyLoss ignore_index). Does your Transformer learn to add? Once you have this, swole doge project: build a calculator clone in GPT, for all of +-*/. Not an easy problem. You may need Chain of Thought traces.\n",
        "\n",
        "- Where to get a dataset? Create on yourself? [Yourself]\n",
        "  - write a script that randomized two numbers a and b.\n",
        "  - loop over n steps and record the results in a text file.\n",
        "- How to tokenize the input?\n",
        "  - Char level?\n",
        "  - Tokens?\n",
        "  - See below for some ideas.\n",
        "- Train a simple GPT on the dataset like you would on any other text. What are the outputs? Why?\n",
        "- How would you train in reverse order?\n",
        "\n",
        "# Try 1\n",
        "- Simplest version of a calculator 0 - 9 + 0 - 9 = 00 - 18\n",
        "- one data set would be blocksize 6.\n",
        "- how much data could I create? The number of combinations?\n",
        "  - 81 combinations only? That is not a lot and I would think that the neural net can just remember these!\n",
        "  - Due to the lack of data the network should be able to remember all the data making a perfect calculator.\n",
        "- I just have to mask the last to blocks.\n",
        "- Hypotheis was wrong, my current approach results in a uniform distribution. (log(12))\n",
        "  - Dataset is to small\n",
        "  - No position - specific modeling.\n"
      ],
      "metadata": {
        "id": "NXg2NidaWDY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# create randomized and bigger dataset\n",
        "text = ''\n",
        "for _ in range(1000):\n",
        "    i = random.randint(0, 9)\n",
        "    j = random.randint(0, 9)\n",
        "    if (i+j) < 10:\n",
        "      result = f\"{i}+{j}=0{i+j}\"\n",
        "    else:\n",
        "      result = f\"{i}+{j}={i+j}\"\n",
        "\n",
        "    text += str(result) + '_'\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for ch, i in stoi.items()}\n",
        "\n",
        "def encode(s):\n",
        "    return [stoi[c] for c in s]\n",
        "\n",
        "def decode(l):\n",
        "    return ''.join(itos[i] for i in l)"
      ],
      "metadata": {
        "id": "UsIyj45hkDkK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwlQOP3rkWdb",
        "outputId": "d7b1b66b-ab44-4cba-af77-e3d9f6399195"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['+', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', '_']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encode(\"9+9=18_\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z0zkhNimU2J",
        "outputId": "54b79fb4-c5c3-43a9-bc56-a310ba31202e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 0, 10, 11, 2, 9, 12]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try a simple network takes in a integer tensor and outputs a integer tensor\n",
        "\n",
        "import torch\n",
        "\n",
        "block_size = 4\n",
        "target_size = 2\n",
        "\n",
        "data = encode(text)\n",
        "\n",
        "X, Y = [], []\n",
        "\n",
        "for i in range((len(data) - block_size)):\n",
        "    context = data[i : i + block_size]\n",
        "    target  = data[i + 1 : i + block_size + 1]\n",
        "\n",
        "    if i < 3:\n",
        "      print(decode(context), \"->\", decode(target))\n",
        "\n",
        "    X.append(context)\n",
        "    Y.append(target)\n",
        "\n",
        "X = torch.tensor(X)  # shape (N, 4)\n",
        "Y = torch.tensor(Y)  # shape (N, 2)\n",
        "\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97Ex-qyXmXxQ",
        "outputId": "f7d58350-2128-4898-d104-110313bbeaeb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9+8= -> +8=1\n",
            "+8=1 -> 8=17\n",
            "8=17 -> =17_\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6996, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "embed_dim = 100  # Hyperparam\n",
        "\n",
        "model  = nn.Sequential(\n",
        "    nn.Embedding(vocab_size, embed_dim),   # B, T -> B, T, embed\n",
        "    nn.Linear(embed_dim, 100),              # (B, T, embed_dim) -> (B, T, 32)\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, vocab_size)              # (B, T, 32) -> (B, T, vocab_size)\n",
        ")"
      ],
      "metadata": {
        "id": "3Ohz2Z-OrhdZ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.AdamW(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "MdLnLRwttqFV"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1000):\n",
        "    logits = model(X)\n",
        "    B, T, C = logits.shape\n",
        "\n",
        "    logits_flat = logits.view(B*T, C)\n",
        "    targets_flat = Y.view(B*T)\n",
        "\n",
        "    loss = loss_fn(logits_flat, targets_flat)\n",
        "\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, loss = {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "wvnuiLeGtnNC",
        "outputId": "02ab0404-03b1-4076-d645-e1bc681c7333",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss = 2.5782\n",
            "Epoch 100, loss = 1.6728\n",
            "Epoch 200, loss = 1.6706\n",
            "Epoch 300, loss = 1.6701\n",
            "Epoch 400, loss = 1.6699\n",
            "Epoch 500, loss = 1.6698\n",
            "Epoch 600, loss = 1.6698\n",
            "Epoch 700, loss = 1.6697\n",
            "Epoch 800, loss = 1.6697\n",
            "Epoch 900, loss = 1.6697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def generate(model, start_text, max_new_tokens=20):\n",
        "    model.eval()\n",
        "    context = torch.tensor(encode(start_text), dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        context_cond = context[:, -block_size:]\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(context_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Convert to probabilities\n",
        "        probs = F.softmax(logits, dim=-1)  # (1, vocab_size)\n",
        "\n",
        "        # Sample next token\n",
        "        next_id = torch.multinomial(probs, num_samples=1)  # (1, 1)\n",
        "\n",
        "        # Append\n",
        "        context = torch.cat([context, next_id], dim=1)\n",
        "\n",
        "        # Stop if EOS is generated\n",
        "        if next_id.item() == '_':\n",
        "            break\n",
        "\n",
        "    return decode(context.squeeze().tolist())"
      ],
      "metadata": {
        "id": "U93qoMwRv686"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate(model, \"7+3=\"))"
      ],
      "metadata": {
        "id": "eQWZqdgsxmAZ",
        "outputId": "1c61fd20-20c5-4bac-8802-8c400bbb6ecf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7+3=03+2=17=13+4=1+09+18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9JovbhvNNukl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}