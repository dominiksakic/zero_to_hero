{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQyTfzG6ZjzmsA2sAZwY9u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominiksakic/zero_to_hero/blob/main/adv_01_dialated_conv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Goal\n",
        "- implement a dialated Convolutions\n",
        "- link: https://arxiv.org/pdf/1609.03499"
      ],
      "metadata": {
        "id": "f_UfT-VrLDuA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEqQm8txKY_G",
        "outputId": "8db4f7ec-b14d-4601-979e-d01f91b954b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-08 11:55:53--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "names.txt           100%[===================>] 222.80K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2025-07-08 11:55:53 (42.1 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#BOILERPLATE CONVNET\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "DASrFOJXLUpi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "\n",
        "# build vocab and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i : s for s, i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "\n",
        "\n",
        "# build the dataset\n",
        "block_size = 8\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "  for w in words:\n",
        "\n",
        "    #print(w)\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcfToNjILXB9",
        "outputId": "a2d4da0e-fd8c-4f8f-fe6f-ecb527bcba47"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "torch.Size([182625, 8]) torch.Size([182625])\n",
            "torch.Size([22655, 8]) torch.Size([22655])\n",
            "torch.Size([22866, 8]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingWithReshape(nn.Module):\n",
        "  def __init__(self, vocab_size, n_embd):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, n_embd)\n",
        "  \"\"\"\n",
        "  Use transpose to rearrange dimensions.\n",
        "  View wont work unless the tensor is already in the correct memory layout.\n",
        "  Usefull link: https://blog.ezyang.com/2019/05/pytorch-internals/\n",
        "  \"\"\"\n",
        "  def forward(self, x):\n",
        "    # x: (B, T)\n",
        "    x = self.embedding(x) # (B,T,C)\n",
        "    x = x.transpose(1, 2) # (B,C,T)\n",
        "    return x"
      ],
      "metadata": {
        "id": "vN-J4bkPLZz5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10\n",
        "n_hidden = 20\n",
        "block_size = 8\n",
        "\n",
        "model = nn.Sequential(\n",
        "    EmbeddingWithReshape(vocab_size, n_embd),\n",
        "    nn.Conv1d(n_embd, n_hidden, kernel_size=2),\n",
        "    nn.BatchNorm1d(n_hidden),\n",
        "    nn.Tanh(),\n",
        "\n",
        "    nn.Conv1d(n_hidden, n_hidden, kernel_size=2),\n",
        "    nn.BatchNorm1d(n_hidden),\n",
        "    nn.Tanh(),\n",
        "\n",
        "    nn.Conv1d(n_hidden, n_hidden, kernel_size=2),\n",
        "    nn.BatchNorm1d(n_hidden),\n",
        "    nn.Tanh(),\n",
        "\n",
        "    nn.AdaptiveAvgPool1d(1),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(n_hidden, vocab_size),\n",
        ")\n",
        "\n",
        "x = torch.randint(0, vocab_size, (32, block_size))\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "\n",
        "for layer in model:\n",
        "    x = layer(x)\n",
        "    print(f\"{layer.__class__.__name__}: {x.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LscO4_sJLqwj",
        "outputId": "24e7f5a0-8794-4c86-c35d-9748c3de8cee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([32, 8])\n",
            "EmbeddingWithReshape: torch.Size([32, 10, 8])\n",
            "Conv1d: torch.Size([32, 20, 7])\n",
            "BatchNorm1d: torch.Size([32, 20, 7])\n",
            "Tanh: torch.Size([32, 20, 7])\n",
            "Conv1d: torch.Size([32, 20, 6])\n",
            "BatchNorm1d: torch.Size([32, 20, 6])\n",
            "Tanh: torch.Size([32, 20, 6])\n",
            "Conv1d: torch.Size([32, 20, 5])\n",
            "BatchNorm1d: torch.Size([32, 20, 5])\n",
            "Tanh: torch.Size([32, 20, 5])\n",
            "AdaptiveAvgPool1d: torch.Size([32, 20, 1])\n",
            "Flatten: torch.Size([32, 20])\n",
            "Linear: torch.Size([32, 27])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = list(model.parameters())\n",
        "print(f\"Parameters: {sum((p.nelement() for p in parameters))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkOJw0QBLsGi",
        "outputId": "b80345ee-c6f8-4744-acd4-18a9fb6732af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: 3017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "ud = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "  # forward pass\n",
        "  logits = model(Xb)\n",
        "  loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  lr = 0.1 if i < 150000 else 0.01\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0:\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnJBatS_LupQ",
        "outputId": "810d6be2-7c00-4ced-85b9-ed748de02fee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/ 200000: 3.3641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BOILERPLATE END"
      ],
      "metadata": {
        "id": "mceiE_GfL1DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is a dialted Convolution?\n",
        "- A dialted convolution introduces gaps between kernel elements. In 1D, this means the filter covers a wider range of input elements without increasing the number of parameters.\n",
        "\n",
        "- main idea: each layer covers a sparse pattern, but the full network sees a dense pattern\n",
        "\n",
        "# Kernel Example\n",
        "  - Input : x0 x1 x2 x3 x4 x5 x6\n",
        "  - Conv-k : x0 x1 x2\n",
        "  - dConv-k: x0    x2    x4\n",
        "\n",
        "# Layer example\n",
        "## Model L0 d=1 -> L1 d=2 -> L2 d=4\n",
        "\n",
        "- Standard convolution/Dialation 1\n",
        "- [x0, x1, x2] → y0\n",
        "- [x1, x2, x3] → y1\n",
        "- [x2, x3, x4] → y2\n",
        "- [x3, x4, x5] → y3\n",
        "- [x4, x5, x6] → y4\n",
        "\n",
        "- Dialation = 2\n",
        "- [x0,   x2,   x4] → z0\n",
        "- [x1,   x3,   x5] → z1\n",
        "- [x2,   x4,   x6] → z2\n",
        "\n",
        "- Dialation = 4\n",
        "- [x0, x4, --] → w0\n",
        "- [x1, x5, --] → w1\n",
        "\n",
        "# Summary of Coverage\n",
        "- x0   | L0, L1, L2\n",
        "- x1   | L0, L1, L2\n",
        "- x2   | L0, L1\n",
        "- x3   | L0, L1\n",
        "- x4   | L0, L1, L2\n",
        "- x5   | L0, L1, L2\n",
        "- x6   | L0, L1\n",
        "\n",
        "- --> Dialted convolutions skip information, but stacking them with increasing dialation lets the network:\n",
        "  - Cover all inputs\n",
        "  - See both local nad global context\n",
        "  - grow the receptive field exponentially"
      ],
      "metadata": {
        "id": "rPzSMpRjQW0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The gensis of Dialted Convolution\n",
        "- Goal is to build it up from toy examples, to understand it all.\n",
        "\n"
      ],
      "metadata": {
        "id": "9oGMjceQK2xD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([0., 1., 2., 3., 4., 5., 6.])\n",
        "kernel = torch.tensor([1., 10., 100.])\n",
        "\n",
        "output = []\n",
        "\n",
        "for t in range(x.shape[0] - kernel.shape[0] + 1):  # (T - K + 1)\n",
        "    window = x[t:t+3]\n",
        "    conv = (window * kernel).sum()\n",
        "    output.append(conv.item())\n",
        "\n",
        "# Problem output shrink\n",
        "print(\"Standard convolution output:\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "ZLz2qIHvLEgm",
        "outputId": "f894e715-3a4d-4bf7-c497-130e610f48c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard convolution output:\n",
            "[210.0, 321.0, 432.0, 543.0, 654.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dilation = 2\n",
        "output = []\n",
        "\n",
        "for t in range(x.shape[0] - dilation*2):\n",
        "  i0 = t\n",
        "  i1 = t + dilation\n",
        "  i2 = t + 2*dilation\n",
        "  window = torch.stack([x[i0], x[i1], x[i2]])\n",
        "  conv = (window * kernel).sum()\n",
        "  output.append(conv.item())\n",
        "\n",
        "print(\"\\nDilated convolution (d=2) output:\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "-T0bApHxLYh5",
        "outputId": "ac47ae26-6d0d-4b4c-f341-456217c6360e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dilated convolution (d=2) output:\n",
            "[420.0, 531.0, 642.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0., 1., 2., 3., 4., 5., 6.])\n",
        "kernel = torch.tensor([1., 10., 100.])\n",
        "\n",
        "def dilated_conv_1d_same(x, kernel, dilation):\n",
        "    K = kernel.shape[0]\n",
        "    pad = dilation * ((K - 1) // 2)\n",
        "    x_padded = torch.nn.functional.pad(x, (pad, pad))\n",
        "\n",
        "    output = []\n",
        "\n",
        "    for t in range(x.shape[0]):\n",
        "        i0 = t\n",
        "        i1 = t + dilation\n",
        "        i2 = t + 2 * dilation\n",
        "        if i2 >= x_padded.shape[0]:\n",
        "            break  # prevent out-of-bounds\n",
        "        window = torch.stack([\n",
        "            x_padded[i0],\n",
        "            x_padded[i1],\n",
        "            x_padded[i2],\n",
        "        ])\n",
        "        conv = (window * kernel).sum()\n",
        "        output.append(conv.item())\n",
        "    return torch.tensor(output)\n",
        "\n",
        "# Layer 0: dilation=1\n",
        "y0 = dilated_conv_1d_same(x, kernel, dilation=1)\n",
        "print(f\"L0 (d=1): {y0}\")\n",
        "print(f\"L0 element: {y0.shape}\")\n",
        "\n",
        "# Layer 1: dilation=2\n",
        "y1 = dilated_conv_1d_same(y0, kernel, dilation=2)\n",
        "print(f\"L1 (d=2): {y1}\")\n",
        "print(f\"L1 element: {y1.shape}\")\n",
        "\n",
        "# Layer 2: dilation=4\n",
        "y2 = dilated_conv_1d_same(y1, kernel, dilation=4)\n",
        "print(f\"L2 (d=4): {y2}\")\n",
        "print(f\"L2 element: {y2.shape}\")\n"
      ],
      "metadata": {
        "id": "oPGLsjHyOrv7",
        "outputId": "5e6401d4-958f-42ed-bc9d-080010699cf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L0 (d=1): tensor([100., 210., 321., 432., 543., 654.,  65.])\n",
            "L0 element: torch.Size([7])\n",
            "L1 (d=2): tensor([33100., 45300., 57610., 69930., 12251.,  6972.,  1193.])\n",
            "L1 element: torch.Size([7])\n",
            "L2 (d=4): tensor([1556100., 1150200.,  695400.,  699300.,  155610.,  115020.,   69540.])\n",
            "L2 element: torch.Size([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytroch implementation\n",
        "class DialatedConvolution(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
        "    super().__init__()\n",
        "    self.kernel_size = kernel_size\n",
        "    self.padding = dilation * (kernel_size - 1)\n",
        "    self.conv = nn.Conv1d(\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        dilation=dilation\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Pad left side only.\n",
        "    x = F.pad(x, (self.padding, 0))\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "b--ThpE3z6E-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10\n",
        "n_hidden = 200\n",
        "block_size = 8\n",
        "\n",
        "model = nn.Sequential(\n",
        "    EmbeddingWithReshape(vocab_size, n_embd),\n",
        "    DialatedConvolution(n_embd, n_hidden, kernel_size=2, dilation=1),\n",
        "    nn.BatchNorm1d(n_hidden),\n",
        "    nn.Tanh(),\n",
        "\n",
        "    DialatedConvolution(n_hidden, n_hidden, kernel_size=2, dilation=2),\n",
        "    nn.BatchNorm1d(n_hidden),\n",
        "    nn.Tanh(),\n",
        "\n",
        "    DialatedConvolution(n_hidden, n_hidden, kernel_size=2, dilation=4),\n",
        "    nn.BatchNorm1d(n_hidden),\n",
        "    nn.Tanh(),\n",
        "\n",
        "    nn.AdaptiveAvgPool1d(1),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(n_hidden, vocab_size),\n",
        ")\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "8nwv__422Sxo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = list(model.parameters())\n",
        "print(f\"Parameters: {sum((p.nelement() for p in parameters))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOJ4auWI33XS",
        "outputId": "028f019f-1012-4f88-e1ec-e6b4a11a9240"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: 171497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "  Xb, Yb = Xtr[ix].to(device), Ytr[ix].to(device)\n",
        "\n",
        "  # forward pass\n",
        "  logits = model(x.to(device))\n",
        "  loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  lr = 0.1 if i < 150000 else 0.01\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0:\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYNIDrNy34Ig",
        "outputId": "f321036c-5d55-4e6a-f880-a6430386d652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/ 200000: 3.3155\n",
            "  10000/ 200000: 2.7720\n",
            "  20000/ 200000: 2.9481\n",
            "  30000/ 200000: 2.7377\n",
            "  40000/ 200000: 2.7207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
      ],
      "metadata": {
        "id": "EbK9Mdrw4OTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def split_loss(split):\n",
        "  model.eval()\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "\n",
        "  x = x.to(device)\n",
        "  y = y.to(device)\n",
        "\n",
        "  logits = model(x)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')\n",
        ""
      ],
      "metadata": {
        "id": "uTMU0K8D4LOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size\n",
        "    context = context.to(device)\n",
        "    while True:\n",
        "      logits = model(torch.tensor([context]))\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      # sample from the distribution\n",
        "      ix = torch.multinomial(probs, num_samples=1).item()\n",
        "      # shift the context window and track the samples\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "id": "T4dFuXhI4PFM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}